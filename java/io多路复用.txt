
参考
http://blog.csdn.net/tennysonsky/article/details/45745887

+--
	同步，可以理解为在执行完一个函数或方法之后，一直等待系统（这里可以理解成内核）返回值或消息，这时程序是出于阻塞的，只有接收到返回的值或消息后才往下执行其他的命令。 
+--
	异步，执行完函数或方法后，不必阻塞性地等待返回值或消息，只需要向系统委托一个异步过程，那么当系统接收到返回值或消息时，系统会自动触发委托的异步过程，从而完成一个完整的流程
+--
	对于写程序，同步往往会阻塞，没有数据过来，我就等着，异步则不会阻塞，没数据来我干别的事，有数据来去处理这些数据。

+--
	同步在一定程度上可以看做是单线程，这个线程请求一个方法后就待这个方法给他回复，否则他不往下执行（死心眼）。 
	异步在一定程度上可以看做是多线程的（废话，一个线程怎么叫异步），请求一个方法后，就不管了，继续执行其他的方法。
+--
	I/O 多路复用技术是 为了解决进程或线程阻塞到某个 I/O 系统调用而出现的技术，使进程不阻塞于某个特定的 I/O 系统调用。
+--
	select()，poll()，epoll()都是I/O多路复用的机制。
+--
	I/O多路复用通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪，就是这个文件描述符进行读写操作之前），能够通知程序进行相应的读写操作。
+--
	select()，poll()，epoll()本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个 读写过程是阻塞的，
	而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。
+--
	与多线程和多进程相比，I/O 多路复用的最大优势是系统开销小，系统不需要建立新的进程或者线程，也不必维护这些线程和进程。
+--
	文件描述符fd(File descriptor)
	文件描述符简称fd。文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表，用以标明每一个被进程所打开的文件和socket。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。第一个打开的文件是0，第二个是1，依此类推。读写文件也需要使用文件描述符来指定待读写的文件。Unix 操作系统通常给每个进程能打开的文件数量强加一个限制。
	在Windows操作系统上，文件描述符被称作 文件句柄(指针)。Windows服务器打开文件的句柄极限设置为16,384。此数量可以在任务管理器的性能摘要中监视。

+--
	linux下，文件描述符分为“用户级限制”和“系统级限制”

	每个用户登录后执行的程序占用文件描述符的总数
	1001   lsof -u www | wc -l
    	   lsof -u data0 | wc -l
    本次登录的session其文件描述符的限制
 	1004   ulimit -n
 	1005  cat /etc/security/limits.conf

 	查看系统级限制
 	1006  sysctl -a | grep fs.file-max
 	1007  cat /etc/sysctl.conf

+--
	函数定义
	int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
	select()系统调用--监视并等待多个文件描述符的属性变化（可读、可写或错误异常）。
		     select()函数返回后，可以通过遍历 fdset，来找到就绪的描述符
		参数
			nfds: 要监视的文件描述符的范围
			readfd: 监视的可读描述符集合，只要有文件描述符即将进行读操作，这个文件描述符就存储到这。
			writefds: 监视的可写描述符集合。
			exceptfds: 监视的错误异常描述符

    select()的缺点在于：
	1）每次调用 select()，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大，同时每次调用 select() 都需要在内核遍历传递进来的所有 fd，这个开销在 fd 很多时也很大。
	2）单个进程能够监视的文件描述符的数量存在最大限制，在 linux 上一般为 1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低。

+--
	select() 和 poll() 系统调用的本质一样,前者在 BSD UNIX 中引入的，后者在 System V 中引入的。
	在本质上没有多大差别,管理多个描述符也是进行轮询，根据描述符的状态进行处理，
	但是 poll() 没有最大文件描述符数量的限制（但是数量过大后性能也是会下降）。
	poll() 和 select() 同样存在一个缺点就是，包含大量  文件描述符的数组被整体复制于 用户态和内核的地址空间之间 ，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大

	函数定义
	int poll(struct pollfd *fds, nfds_t nfds, int timeout);
	poll() 功能：
		监视并等待多个文件描述符的属性变化。

	参数
	fds: 不同与 select() 使用三个位图来表示三个 fdset 的方式，poll() 使用一个 pollfd 的指针实现
	pollfd 结构体数组，其中包括了你想测试的 文件描述符和事件, 事件由结构中事件域 events 来确定，调用后实际发生的时间将被填写在结构体的 revents 域。
	struct pollfd{
	int fd;         /* 文件描述符 */
	short events;   /* 等待的事件 */
	short revents;  /* 实际发生了的事件 */
	}; 

	nfds: 用来指定第一个参数数组元素个数。
	timeout: 指定等待的毫秒数

	总结
	poll() 的实现和 select() 非常相似，只是描述 fd 集合的方式不同，poll() 使用 pollfd 结构而不是 select() 的 fd_set 结构，其他的都差不多。

+--
	epoll 是在 2.6 内核中提出的，是之前的 select() 和 poll() 的增强版本。相对于 select() 和 poll() 来说，epoll 更加灵活，没有描述符限制。epoll 使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的 copy 只需一次。

	函数定义
	epoll 操作过程需要三个接口
	#include <sys/epoll.h>  
	int epoll_create(int size);  
	int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);  
	int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);  


+--
	epoll 的优点主要是一下几个方面：
	1）监视的描述符数量不受限制，它所支持的 FD 上限是最大可以打开文件的数目，这个数字一般远大于 2048,举个例子,在 1GB 内存的机器上大约是 10 万左右，具体数目可以 cat /proc/sys/fs/file-max 察看,一般来说这个数目和系统内存关系很大。select() 的最大缺点就是进程打开的 fd 是有数量限制的。这对于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache 就是这样实现的)，不过虽然 Linux 上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。

	2）I/O 的效率不会随着监视 fd 的数量的增长而下降。select()，poll() 实现需要自己不断轮询所有 fd 集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而 epoll 其实也需要调用 epoll_wait() 不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪 fd 放入就绪链表中，并唤醒在 epoll_wait() 中进入睡眠的进程。虽然都要睡眠和交替，但是 select() 和 poll() 在“醒着”的时候要遍历整个 fd 集合，而 epoll 在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的 CPU 时间。这就是回调机制带来的性能提升。

	3）select()，poll() 每次调用都要把 fd 集合从用户态往内核态拷贝一次，而 epoll 只要一次拷贝，这也能节省不少的开销。
+--

	socket连接简单理解（ip+端口号）就是socket
+--
	io
	网络IO和磁盘IO
	异步和并发 I/O
		异步 I/O (AIO) 是在 OS 级上设置的
		并发 I/O (CIO) 是 JFS2 采用的 AIX 特性
+--
	http://www.rowkey.me/blog/2016/01/18/io-model/
	【************】
	IO模型，都会牵扯到同步、异步、阻塞、非阻塞
	IO有内存IO、网络IO和磁盘IO三种，通常我们说的IO指的是后两者。
	阻塞和非阻塞，是函数/方法的实现方式，即在数据就绪之前是立刻返回还是等待，即发起IO请求是否会被阻塞。
	以文件IO为例,一个IO读过程是文件数据从磁盘→内核缓冲区→用户内存的过程。同步与异步的区别主要在于数据从内核缓冲区→用户内存这个过程需不需要用户进程等待，即实际的IO读写是否阻塞请求进程。(网络IO把磁盘换做网卡即可)

+--
	IO模型
		同步阻塞:调用会一直阻塞直到数据接收完毕，就是一个同步阻塞的IO方式。这也是最简单的IO模型，在通常fd较少、就绪很快的情况下使用是没有问题的。
		同步非阻塞:编程中对socket设置O_NONBLOCK即可。但此方式仅仅针对网络IO有效，对磁盘IO并没有作用。
		IO复用:select、poll【轮询，每次调用全部把fd复制到内核】，epoll事件触发，回调
	
+--
	网络编程模型
		BIO
		NIO
		AIO

				同步阻塞IO		伪异步IO	NIO				AIO
客户端数目 ：	IO线程	1 : 1	m : n		m : 1			m : 0
IO模型			同步阻塞IO		同步阻塞IO	同步非阻塞IO	异步非阻塞IO
吞吐量			低				中			高				高
编程复杂度		简单			简单		非常复杂		复杂

+--
	http://weiruoyu.blog.51cto.com/951650/803984
	http://www.weiruoyu.cn/?p=507
	一、影响Linux服务器性能的因素
	1. 操作系统级
	CPU
	内存
	磁盘I/O带宽
	网络I/O带宽
	2. 程序应用级
	二、系统性能评估标准
	影响性能因素
	影响性能因素	评判标准
					好	坏	糟糕
	CPU	user% + sys%< 70%	user% + sys%= 85%	user% + sys% >=90%
	内存	Swap In(si)＝0
			Swap Out(so)＝0
			Per CPU with 10 page/s	More Swap In & Swap Out
	磁盘	iowait % < 20%	iowait % =35%	iowait % >= 50%

	其中：
	%user：表示CPU处在用户模式下的时间百分比。
	%sys：表示CPU处在系统模式下的时间百分比。
	%iowait：表示CPU等待输入输出完成时间的百分比。
	swap in：即si，表示虚拟内存的页导入，即从SWAP DISK交换到RAM
	swap out：即so，表示虚拟内存的页导出，即从RAM交换到SWAP DISK。
	三、系统性能分析工具
	1.常用系统命令
	Vmstat、sar、iostat、netstat、free、ps、top等
	2.常用组合方式
	o 用vmstat、sar、iostat检测是否是CPU瓶颈
	o 用free、vmstat检测是否是内存瓶颈
	o 用iostat检测是否是磁盘I/O瓶颈
	o 用netstat检测是否是网络带宽瓶颈
	四、Linux性能评估与优化
	1. 系统整体性能评估(uptime命令)
	[root@server ~]# uptime
	16:38:00 up 118 days, 3:01, 5 users, load average: 1.22, 1.02, 0.91
	这里需要注意的是：load average这个输出值，这三个值的大小一般不能大于系统CPU的个数，例如，本输出中系统有8个CPU,如果load average的三个值长期大于8时，说明CPU很繁忙，负载很高，可能会影响系统性能，但是偶尔大于8时，倒不用担心，一般不会影响系统性能。相反，如 果load average的输出值小于CPU的个数，则表示CPU还有空闲的时间片，比如本例中的输出，CPU是非常空闲的。
	2. CPU性能评估
	(1)利用vmstat命令监控系统CPU
	该命令可以显示关于系统各种资源之间相关性能的简要信息，这里我们主要用它来看CPU一个负载情况。
	下面是vmstat命令在某个系统的输出结果：


	4.磁盘I/O性能评估
	(1)磁盘存储基础
		熟悉RAID存储方式，可以根据应用的不同，选择不同的RAID方式。
		尽可能用内存的读写代替直接磁盘I/O，使频繁访问的文件或数据放入内存中进行操作处理，因为内存读写操作比直接磁盘读写的效率要高千倍。
		将经常进行读写的文件与长期不变的文件独立出来，分别放置到不同的磁盘设备上。
		对于写操作频繁的数据，可以考虑使用裸设备代替文件系统。    使用裸设备的优点有：
		数据可以直接读写，不需要经过操作系统级的缓存，节省了内存资源，避免了内存资源争用。
		避免了文件系统级的维护开销，比如文件系统需要维护超级块、I-node等。
		避免了操作系统的cache预读功能，减少了I/O请求。    使用裸设备的缺点是：
		数据管理、空间管理不灵活，需要很专业的人来操作。   
	 (2)利用iostat评估磁盘性能
	 	iostat -d 2 3
	 	Blk_read/s表示每秒读取的数据块数。
		Blk_wrtn/s表示每秒写入的数据块数。
		Blk_read表示读取的所有块数。
		Blk_wrtn表示写入的所有块数。
		可 以通过Blk_read/s和Blk_wrtn/s的值对磁盘的读写性能有一个基本的了解，如果Blk_wrtn/s值很大，表示磁盘的写操作很频繁，可 以考虑优化磁盘或者优化程序，如果Blk_read/s值很大，表示磁盘直接读取操作很多，可以将读取的数据放入内存中进行操作。
		对于这两个选项的值没有一个固定的大小，根据系统应用的不同，会有不同的值，但是有一个规则还是可以遵循的：长期的、超大的数据读写，肯定是不正常的，这种情况一定会影响系统性能。    
	(3)利用sar评估磁盘性能
		sar -d 2 3
		await表示平均每次设备I/O操作的等待时间（以毫秒为单位）。
		svctm表示平均每次设备I/O操作的服务时间（以毫秒为单位）。
		%util表示一秒中有百分之几的时间用于I/O操作。
		对以磁盘IO性能，一般有如下评判标准：
		正常情况下svctm应该是小于await值的，而svctm的大小和磁盘性能有关，CPU、内存的负荷也会对svctm值造成影响，过多的请求也会间接的导致svctm值的增加。
		await值的大小一般取决与svctm的值和I/O队列长度以及I/O请求模式，如果svctm的值与await很接近，表示几乎没有I/O等待，磁盘 性能很好，如果await的值远高于svctm的值，则表示I/O队列等待太长，系统上运行的应用程序将变慢，此时可以通过更换更快的硬盘来解决问题。
		%util项的值也是衡量磁盘I/O的一个重要指标，如果%util接近100%，表示磁盘产生的I/O请求太多，I/O系统已经满负荷的在工作，该磁盘可能存在瓶颈。长期下去，势必影响系统的性能，可以通过优化程序或者通过更换更高、更快的磁盘来解决此问题。


	5. 网络性能评估
	（1）通过ping命令检测网络的连通性
	（2）通过netstat -i组合检测网络接口状况
	（3）通过netstat -r组合检测系统的路由表信息
	（4）通过sar -n组合显示系统的网络运行状态	
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--
+--



