


LVS+HAProxy
负载均衡解决方案

你知道这两个的本质区别是啥吗 


7层0SI模型
TCP/IP协议族

Layer
Name 				OSI protocol 			TCP/IP protocols
7 Application 		
6 Presentation 
5 Session
4 Transport   			   tcp udp
3 Network                  IP
2 Data Link
1 Physical


LVS是Linux Virtual Server的简写，意即Linux虚拟服务器
haproxy  是一个使用C语言编写的自由及开放源代码软件
		 提供高可用性、负载均衡，
		 以及基于TCP和HTTP的应用程序代理。



一台物理机器可以分配多少个虚拟主机

负载均衡系统必须建立网络链接的基础。面对传输层上的

数据通过网络--轮询算法--分发到 Real Server A 或者 Real Server B





OSI 模型 ip协议在第三层网络层
		 tcp/udp在第四层传输层

	lvs负载均衡系统必须基于OSI模型之上。	 

	LVS可以处理4层协议内容，比如TCP的目标端口。



负载对象是一个个的链接，链接需要IP+端口


lvs是四层  代理
haproxy是七层 代理
这两个都是  负载均衡
主从
什么是负载均衡， 什么是高可用 



负载均衡与高可用架构：Nginx + Keepalived（主备模式），
Nginx 使用反向代理实现七层负载均衡。


Nginx 是一款自由的、开源的、高性能HTTP服务器和反向代理服务器，
也是一个IMAP、POP3、SMTP代理服务器。


Keepalived 是一个基于VRRP协议来实现的服务高可用方案，
可以利用其来避免IP单点故障，
类似的工具还有heartbeat、corosync、pacemaker。




但是它一般不会单独出现，
而是与其它负载均衡技术（如lvs、haproxy、nginx）
一起工作来达到集群的高可用。


linux负载均衡总结性说明（四层负载/七层负载）
http://www.cnblogs.com/kevingrace/p/6137881.html
一，什么是负载均衡
1）负载均衡（Load Balance）建立在现有网络结构之上，
	它提供了一种廉价有效透明的方法
	扩展网络设备和服务器的带宽、
	增加吞吐量、
	加强网络数据处理能力、
	提高网络的灵活性和可用性。

负载均衡有两方面的含义：
	首先，大量的并发访问或数据流量分担到多台节点设备上分别处理，
		减少用户等待响应的时间；
	其次，单个重负载的运算分担到多台节点设备上做并行处理，
		每个节点设备处理结束后，将结果汇总，
		返回给用户，系统处理能力得到大幅度提高。

2）简单来说就是：
	其一是将大量的并发处理转发给后端多个节点处理，减少工作响应时间；
	其二是将单个繁重的工作转发给后端多个节点处理，处理完再返回给负载均衡中心，
	再返回给用户。
	目前负载均衡技术大多数是用于提高诸如在Web服务器、
	FTP服务器和其它关键任务服务器上的Internet服务器程序的可用性和可伸缩性。



二，负载均衡分类
	1）二层负载均衡（mac）
		根据OSI模型分的二层负载，
		一般是用虚拟mac地址方式，
		外部对虚拟MAC地址请求，
		负载均衡接收后分配后端实际的MAC地址响应）
	2）三层负载均衡（ip）
		一般采用虚拟IP地址方式，
		外部对虚拟的ip地址请求，
		负载均衡接收后分配后端实际的IP地址响应）
	3）四层负载均衡（tcp）
		在三次负载均衡的基础上，
		用ip+port接收请求，
		再转发到对应的机器。
	4）七层负载均衡（http）
		根据虚拟的url或IP，
		主机名接收请求，
		再转向相应的处理服务器）。

运维中最常见的四层和七层负载均衡

	1）四层的负载均衡就是基于IP+端口的负载均衡：
	在三层负载均衡的基础上，通过发布三层的IP地址（VIP），
	然后加四层的端口号，来决定哪些流量需要做负载均衡，

	对需要处理的流量进行NAT处理，转发至后台服务器，
	并记录下这个TCP或者UDP的流量是由哪台服务器处理的，

	后续这个连接的所有流量都同样转发到同一台服务器处理。
	对应的负载均衡器称为四层交换机（L4 switch），

	主要分析IP层及TCP/UDP层，实现四层负载均衡。
	此种负载均衡器不理解应用协议（如HTTP/FTP/MySQL等等）。


	实现四层负载均衡的软件有：
	F5：硬件负载均衡器，功能很好，但是成本很高。
	lvs：重量级的四层负载软件
	nginx：轻量级的四层负载软件，带缓存功能，正则表达式较灵活
	haproxy：模拟四层转发，较灵活


------------

	2）七层的负载均衡就是基于虚拟的URL或主机IP的负载均衡：
	在四层负载均衡的基础上（没有四层是绝对不可能有七层的），
	再考虑应用层的特征，比如同一个Web服务器的负载均衡，

	除了根据VIP加80端口辨别是否需要处理的流量，

	还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。

	举个例子，如果你的Web服务器分成两组，
	一组是中文语言的，一组是英文语言的，

	那么七层负载均衡就可以当用户来访问你的域名时，
	自动辨别用户语言，然后选择对应的语言服务器组进行负载均衡处理。
	对应的负载均衡器称为七层交换机（L7 switch），

	除了支持四层负载均衡以外，还有分析应用层的信息，
	如HTTP协议URI或Cookie信息，实现七层负载均衡。
	此种负载均衡器能理解应用协议。


	实现七层负载均衡的软件有：
	haproxy：天生负载均衡技能，全面支持七层代理，会话保持，标记，路径转移；
	nginx：只在http协议和mail协议上功能比较好，性能与haproxy差不多；
	apache：功能较差
	Mysql proxy：功能尚可。


三、两者之间的区别

	SYN（synchronous）是TCP/IP建立连接时使用的握手信号
	客户机和服务器之间建立正常的TCP网络连接时，
	客户机首先发出一个SYN消息，
	服务器使用SYN+ACK应答表示接收到了这个消息，
	最后客户机再以ACK消息响应。


4）总体对比
1.智能性
	七层负载均衡由于具备OIS七层的所有功能，所以在处理用户需求上能更加灵活，
	从理论上讲，七层模型能对用户的所有跟服务端的请求进行修改。
	例如对文件header添加信息，根据不同的文件类型进行分类转发。
	四层模型仅支持基于网络层的需求转发，不能修改用户请求的内容。
2.安全性
	七层负载均衡由于具有OSI模型的全部功能，能更容易抵御来自网络的攻击；
	四层模型从原理上讲，会直接将用户的请求转发给后端节点，无法直接抵御网络攻击。
3.复杂度
	四层模型一般比较简单的架构，容易管理，容易定位问题；
	七层模型架构比较复杂，通常也需要考虑结合四层模型的混用情况，
	出现问题定位比较复杂。
4.效率比
	四层模型基于更底层的设置，通常效率更高，但应用范围有限；
	七层模型需要更多的资源损耗，在理论上讲比四层模型有更强的功能，现在的实现更多是基于http应用。



（*******）
client--nginx--web server
四层就是端口；七层就是具体的应用
有很多情况是端口在，应用死了
1. 隐藏后端网络，
2. 负载均衡；
对外曝光的端口是nginx吗
透明代理；--对外暴露出指定的端口号
nginx对外暴露指定的端口号





代理就是基于一定的层次的 ；

http是七层， tomcat是4层； 
nginx只能识别 http协议和smtp协议；
apache-->tomcat的方向代理配置
nginx也支持四层；
lvs这个软件仅支持四层；
代理就是基于一定的层次的 ；


lvs是四层代理
对四层 OSI
OSI七层模型的四层

四层就是端口；不能识别具体的应用 
端口基本都可以通用了；
80%的程序都是有端口的，通过端口负载到后端
负载均衡到后端啊 ，分摊压力啊 

如果服务器到瓶颈了 
一般有两种方式解决 
向上扩展； 向外扩展
向上就是 使用更多的CPU，内存，磁盘等
向外是扩展服务器
向外就是一个人干不了的活，多个人干，
分摊负载 
这就是负载均衡；

向上扩展不是理想的方式 
往往价格提升一倍，性能不一定一倍，到后面，
如果超出一个临界点后， 向上扩展反而会拉低性能的
这里面学问有很多






分布式
	你去看下分布式的理论吧
	CAP， BASE
	cap：一致性，可用性，分区容错性
	一般分布式系统只能保持两个；
	一般分布式系统保存的是ap，ap：可用性，分区容错性


	BASE就是一种 一致性的这种解决方案 
	分布式系统中常见的一致性实现方式有好多中
	有 NRW，2PC，等等协议 

	不是一两句话能说清楚的 ；

	弱一致性，强制性，最终一致性，因果一致性，
	各种一致性







负载均衡分类
负载均衡所采用的设备对象（软/硬件负载均衡），
应用的OSI网络层次（网络层次上的负载均衡），
及应用的地理结构（本地/全局负载均衡）


	1）软/硬件负载均衡
		一台或多台服务器相应的操作系统上安装一个或多个附加软件来实现负载均衡，
		如DNS Load Balance，CheckPoint Firewall-1 ConnectControl，Keepalive+ipvs等，
		它的优点是基于特定环境，配置简单，使用灵活，成本低廉，可以满足一般的负载均衡需求。
	2）本地/全局负载均衡
	本地负载均衡(Local Load Balance)和全局负载均衡(Global Load Balance，也叫地域负载均衡)
	本地负载均衡是指对本地的服务器群做负载均衡，
	全局负载均衡是指对分别放置在不同的地理位置、有不同网络结构的服务器群间作负载均衡

	3）网络层次上的负载均衡
	 现代负载均衡技术通常操作于网络的第四层或第七层。
	 第四层负载均衡将一个Internet上合法注册的IP地址映射为多个内部服务器的IP地址，
	 对每次 TCP连接请求动态使用其中一个内部IP地址，达到负载均衡的目的。
	 在第四层交换机中，此种均衡技术得到广泛的应用，
	 一个目标地址是服务器群VIP（虚拟 IP，Virtual IP address）连接请求的数据包流经交换机，
	 交换机根据源端和目的IP地址、TCP或UDP端口号和一定的负载均衡策略，
	 在服务器IP和VIP间进行映射，选取服务器群中最好的服务器来处理连接请求。


		七层负载均衡控制应用层服务的内容，提供了一种对访问流量的高层控制方式，
		适合对HTTP服务器群的应用。
		第七层负载均衡技术通过检查流经的HTTP报头，根据报头内的信息来执行负载均衡任务。


负载均衡算法
	1）轮循均衡（Round Robin）
	2）权重轮循均衡（Weighted Round Robin）
	3）随机均衡（Random）
	4）权重随机均衡（Weighted Random）
	5）响应速度均衡（Response Time）
	6）最少连接数均衡（Least Connection）
	7）处理能力均衡
	8）DNS响应均衡（Flash DNS）



六、负载均衡实施要素
	1）性能
		均衡方案对服务器群整体的性能，响应服务器速度
		负载均衡设备自身的性能，避免有大量连接请求时自身性能不足而成为服务瓶颈

	2）可扩展性
	3）灵活性
	4）可靠性
		对服务质量要求较高的站点，负载均衡解决方案应能为服务器群提供完全的容错性和高可用性
		备自身出现故障时，应该有良好的冗余解决方案，提高可靠性

	5）易管理性
		一、命令行接口（CLI：Command Line Interface）
		二、图形用户接口（GUI：Graphical User Interfaces）
		三、SNMP（Simple Network Management Protocol，简单网络管理协议）支持





http应用优化和加速说明-负载均衡
http://www.cnblogs.com/kevingrace/p/6137975.html
	现代企业信息化应用越来越多的采用B/S应用架构来承载企业的关键业务
	企业实施数据集中，应用的扩展性、安全性和可靠性也越来越受到企业的重视


	负载均衡技术通过设置虚拟服务器IP（VIP），
	将后端多台真实服务器的应用资源虚拟成一台高性能的应用服务器，
	通过负载均衡算法，将大量来自客户端的应用请求分配到后端的服务器进行处理。



	Web2.0和B/S技术的迅猛发展，
	HTTP应用逐渐成为当今的主流应用，
	而负载均衡技术也有了很大的发展。


	传统的基于四层端口号进行简单的应用请求转发，
	到目前基于七层内容进行请求的转发和处理。


	尤其是在HTTP协议的优化和加速方面，一些技术逐渐发展成熟，
	TCP连接复用、
	内容缓存、
	TCP缓冲、
	HTTP压缩、
	SSL加速等。
	改善用户访问响应时间、节约广域网链路带宽和服务器资源。


HTTP协议优化和加速技术说明

1、TCP 连接复用（TCP Connection Reuse）
	HTTP 1.0中，客户端的每一个HTTP请求都必须通过独立的TCP连接进行处理，
	而在HTTP 1.1中，对这种方式进行了改进。
	客户端可以在一个TCP连接中发送多个HTTP请求，这种技术叫做HTTP复用（HTTP Multiplexing）

	TCP连接复用是将多个客户端的HTTP请求复用到一个服务器端TCP连接上，
	而HTTP复用则是一个客户端的多个HTTP请求通过一个TCP连接进行处理。
	前者是负载均衡设备的独特功能；
	而后者是HTTP 1.1协议所支持的新功能，目前被大多数浏览器所支持。


	用户和厂商喜欢采用连接复用率来评判一个负载均衡设备的TCP连接复用技术的好坏
	TCP连接复用率是指一段时间内负载均衡设备成功处理的客户端HTTP请求总数与这段时间负载均衡与服务器之间建立的TCP连接总数的比值
	TCP连接复用率=nginx处理http请求数 / nginx与web server建立的tcp链接数总数


	客户端（浏览器）在发送HTTP请求（web server）之前需要先与服务器进行TCP三次握手，
	建立TCP连接，然后发送HTTP请求。服务器（web server）收到HTTP请求后进行处理，
	并将处理的结果发送回客户端，然后客户端和服务器互相发送FIN并在收到FIN的ACK确认后关闭连接。

	一个简单的HTTP请求需要十几个TCP数据包才能处理完成

	采用TCP连接复用技术后，
		客户端（如：ClientA）与负载均衡设备之间进行三次握手并发送HTTP请求。
		负载均衡设备收到请求后，会检测服务器是否存在空闲的长连接，如果不存在，
		服务器将建立一个新连接。当HTTP请求响应完成后，客户端则与负载均衡设备协商关闭连接，
		而负载均衡则保持与服务器之间的这个连接。

		当有其它客户端（如：ClientB）需要发送HTTP请求时，
		负载均衡设备会直接向与服务器之间保持的这个空闲连接发送HTTP请求，
		避免了由于新建TCP连接造成的延时和服务器资源耗费。


2、内容缓存（RAM Caching）
	内容缓存技术将应用服务器中的一些经常被用户访问的热点内容缓存在负载均衡设备的内存中

	缓存静态资源（gif/jpg图片，静态的css/js/html等文本文件）

	用户访问logo.gif的实例来解释内容缓存的工作过程：
		1）当有客户端发起对logo.gif的第一个请求时，
			负载均衡首先会检查本地缓存中是否存在该对象。
			如果不存在这个对象，负载均衡会将这个HTTP请求转发给后端的服务器；
		2）服务器收到对logo.gif的HTTP请求后，将图片内容回应给负载均衡设备；
		3）负载均衡设备将logo.gif对象缓存在内容缓存中，并将其发送给客户端；
		4）后续的其它客户端发起对logo.gif的访问请求时，
			如果负载均衡检测到内容缓存中已经存在该对象，并确认该对象并未失效的话，
			负载均衡直接将该对象返回给客户端，而无需服务器再次发送该对象。

3、TCP缓冲机制
	TCP缓冲是为了解决
	后端服务器网速与客户的前端网络速度不匹配
	而造成的服务器资源浪费的问题




4、HTTP压缩（HTTP Compression）
	HTTP协议在v 1.1中新增了压缩功能，压缩算法本身需要耗费大量的CPU资源，
	因此，负载均衡设备通过对HTTP压缩功能进行支持，
	减轻Web服务器的资源耗费，提高其处理效率




5、SSL加速（SSL Acceleration）
	一般采用SSL协议（即：HTTPS）对HTTP协议进行加密，以保证整个传输过程的安全性。
	在SSL通信中，首先采用非对称密钥技术交换认证信息，
	并交换服务器和浏览器之间用于加密数据的会话密钥，
	然后利用该密钥对通信过程中的信息进行加密和解密。

	SSL是需要耗费大量CPU资源的一种安全技术。

	大多数负载均衡设备均采用SSL加速芯片进行SSL信息的处理。
	这种方式比传统的采用服务器的SSL加密方式提供更高的SSL处理性能，
	从而节省大量的服务器资源，使服务器能够专注于业务请求的处理


	SSL的处理流程如下：
	1）客户端发起HTTPS连接请求，协商传输的加密算法，确认双方身份，并交换会话密钥。
	2）负载均衡收到客户端加密的HTTPS请求后，
		对请求的信息进行解密，然后通过HTTP的方式发送给后端的服务器。
	3）服务器将请求的处理结果返回给负载均衡设备。
	4）负载均衡设备利用会话密钥对请求的结果进行加密，然后将结果返回给客户端。
	5）客户端采用会话密钥对返回结果进行解密，并显示在浏览器上。


	负载均衡设备中实现SSL加速功能，只需要在负载均衡设备上导入SSL证书和密钥即可

	客户端发起对虚拟服务器的HTTPS请求时，
	负载均衡设备自动和客户端进行SSL协议的协商并交换会话密钥。
	客户端发送的请求以及负载均衡返回的响应均采用会话密钥进行加密，
	而负载均衡设备与后端服务器之间则采用HTTP的方式进行请求的发送和处理。

负载均衡设备就可以简单理解从nginx

负载均衡+高可用
LB+HA
http://www.cnblogs.com/kevingrace/category/899066.html



一个nginx返代到后端多个tomcat；
tomcat做负载均衡；

页面统计
pv 30W+， 1000W+
pv：page view
你个页面入口就是一个pv
一个用户可以点击很多网页；
一个用户产生成百上千都正常；

看一个网站的pv，说明有用户
说明网站访问量还可以
不是网站很NB，是有用户的；

对啊，大型门户网站，pv都是  以亿计算的；

ELK
ELK(ElasticSearch, Logstash, Kibana)搭建实时日志分析平台




你像 饿了么，一天的日质量都是  上亿条； 你如何记录；
这还仅仅 是日志；  
这么大的数据量你如何记录；
摩尔定律
原来是用在CPU上现在是用在数据量上
现在说  全球的数据量每18个月就要翻一倍

你想小公司你是接触不到这么大的数据量的；
接触不到也就不用想 怎么解决
还得需要好的平台



-------------------------------------------
Nginx+keepalived双机热备（主从模式）

Keepalived介绍：
	Keepalived是一个基于VRRP协议来实现的服务高可用方案，
	可以利用其来避免IP单点故障，
	类似的工具还有heartbeat、corosync、pacemaker。
	但是它一般不会单独出现，
	而是与其它负载均衡技术（如lvs、haproxy、nginx）
	一起工作来达到集群的高可用。

VRRP协议：
	VRRP全称 Virtual Router Redundancy Protocol，即 虚拟路由冗余协议。
	可以认为它是实现路由器高可用的容错协议，
	即将N台提供相同功能的路由器组成一个路由器组(Router Group)，
	这个组里面有一个master和多个backup，
	但在外界看来就像一台一样，构成虚拟路由器，
	拥有一个虚拟IP（vip，也就是路由器所在局域网内其他机器的默认路由），
	占有这个IP的master实际负责ARP相应和转发IP数据包，
	组中的其它路由器作为备份的角色处于待命状态。
	master会发组播消息，
	当backup在超时时间内收不到vrrp包时就认为master宕掉了，
	这时就需要根据VRRP的优先级来选举一个backup当master，
	保证路由器的高可用。




web前端放置nginx负载均衡,同时结合keepalived对前端nginx实现HA高可用。

1）nginx进程基于Master+Slave(worker)多进程模型，自身具有非常稳定的子进程管理功能。
	在Master进程分配模式下，Master进程永远不进行业务处理，只是进行任务分发，
	从而达到Master进程的存活高可靠性，
	Slave(worker)进程所有的业务信号都 由主进程发出，
	Slave(worker)进程所有的超时任务都会被Master中止，属于非阻塞式任务模型。

2）Keepalived是Linux下面实现VRRP备份路由的高可靠性运行件。
	基于Keepalived设计的服务模式能够真正做到主服务器和备份服务器故障时IP瞬间无缝交接。
	二者结合，可以构架出比较稳定的软件LB方案。


keepalived与heartbeat/corosync等比较：
	Heartbeat、Corosync、Keepalived这三个集群组件我们到底选哪个好呢？
	Heartbeat、Corosync是属于同一类型，Keepalived与Heartbeat、Corosync，根本不是同一类型的

	Keepalived使用的vrrp协议方式，虚拟路由冗余协议 (Virtual Router Redundancy Protocol，简称VRRP)；
	Heartbeat或Corosync是基于主机或网络服务的高可用方式；



	keepalived的目的是模拟路由器的高可用，
	Heartbeat或Corosync的目的是实现Service的高可用

	前端高可用的组合
	LVS+Keepalived、Nginx+Keepalived、HAproxy+Keepalived

	而Heartbeat或Corosync是实现服务的高可用
	Heartbeat v3(Corosync)+Pacemaker+NFS+Httpd 实现Web服务器的高可用


	Heartbeat v3(Corosync)+Pacemaker+NFS+MySQL 实现MySQL服务器的高可用



双机高可用方法目前分为两种：

1）双机主从模式：
				前端使用两台服务器，一台主服务器和一台热备服务器，正常情况下，
				主服务器绑定一个公网虚拟IP，提供负载均衡服务，热备服务器处于空闲状态；
				当主服务器发生故障时，热备服务器接管主服务器的公网虚拟IP，提供负载均衡服务；
				但是热备服务器在主机器不出现故障的时候，永远处于浪费状态，对于服务器不多的网站，该方案不经济实惠。
2）双机主主模式：
				即前端使用两台负载均衡服务器，互为主备，且都处于活动状态，
				同时各自绑定一个公网虚拟IP，提供负载均衡服务；
				当其中一台发生故障时，另一台接管发生故障服务器的公网虚拟IP
				（这时由非故障机器一台负担所有的请求）。
				这种方案，经济实惠，非常适合于当前架构环境


粒子【arp路由转换】
高可用性HA（High Availability）
两台机器同时完成一项功能，比如数据库服务器，平常只有一台机器对外提供服务，
另一台机器作为热备，当这台机器出现故障时，自动动态切换到另一台热备的机器。

怎么实现故障检测的那？
		 心跳。
		 	采用定时发送一个数据包，
		 	如果机器多长时间没响应，
		 	就认为是发生故障，
		 	自动切换到热备的机器上去。


		怎么实现自动切换那？
		虚IP。
			何为虚IP那，就是一个未分配给真实主机的IP
			就是说对外提供数据库服务器的主机除了有一个真实IP外还有一个虚IP
			两个IP中的 任意一个都可以连接到这台主机，所有项目中数据库链接一项配置的都是这个虚IP
			当服务器发生故障无法对外提供服务时，动态将这个虚IP切换到备用主机


		其实现原理主要是靠TCP/IP的ARP协议。（路由器/路由表）
		ip地址只是一个逻辑 地址，在以太网中MAC地址才是真正用来进行数据传输的物理地址
		每台主机中都有一个ARP高速缓存，存储同一个网络内的IP地址与MAC地址的对应关系，

		以太网（局域网）中的主机发送数据时会先从这个缓存中查询目标IP对应的MAC地址，会向这个MAC地址发送数据
		操作系统会自动维护这个缓存。这就是整个实现 的关键。


		(192.168.1.219) at 00:21:5A:DB:68:E8 [ether] on bond0
		(192.168.1.217) at 00:21:5A:DB:68:E8 [ether] on bond0
		(192.168.1.218) at 00:21:5A:DB:7F:C2 [ether] on bond0

		192.168.1.217、192.168.1.218是两台真实的电脑，
		192.168.1.217为对外提供数据库服务的主机。
		192.168.1.218为热备的机器。
		192.168.1.219为虚IP。

		注意此时虚拟ip-219、主服务器217的MAC地址是相同的。

		217宕机后的arp缓存
		(192.168.1.219) at 00:21:5A:DB:7F:C2 [ether] on bond0
		(192.168.1.217) at 00:21:5A:DB:68:E8 [ether] on bond0
		(192.168.1.218) at 00:21:5A:DB:7F:C2 [ether] on bond0 

		当218 发现217宕机后会向网络发送一个ARP数据包，
		告诉所有主机192.168.1.219这个IP对应的MAC地址是00:21:5A:DB:7F:C2
		这样所有发送到219的数据包都会发送到mac地址为00:21:5A:DB:7F:C2的机器，
		也就是218的机器



-----------------------------------------------------------------------
http://www.cnblogs.com/kevingrace/p/8144539.html
		集群中的session解决方案

		用户--请求--负载均衡代理nginx--服务器A--登录--服务器A保存用户信息
		用户--请求--负载均衡代理nginx--服务器B--服务器B没有登录信息--重新登录

		对用户来说是不可忍受的

		这就是Session问题
		1）Session会话保持（案例：Nginx、Haproxy）
		2）Session会话复制（案例：Tomcat）
		3）Session会话共享（案例：Memcached、Redis）



		 一、Session会话保持
		 负载均衡进行请求分发的时候保证每个客户端固定的访问到后端的同一台应用服务器。

		================Nginx 做负载均衡的Session保持================
		nginx的upstream目前支持5种方式的分配方式
		通用的Session解决方法，ip_hash和url_hash
		ip_hash
		每个请求按访问ip的hash结果分配，
		这样每个访客固定访问一个后端服务器，
		达到了Session保持的方法

		upstream bakend {
		   ip_hash;
		   server192.168.0.11:80;
		   server192.168.0.12:80;
		 }

		================Haproxy做负载均衡的Session保持================
		Haproxy作为一个优秀的反向代理和负载均衡软件，也提供了多种Session保持的方法，下面列举了两种最常用的：
		1) 源地址 Hash
		haroxy 将用户IP经过hash计算后指定到固定的真实服务器上
			（类似于nginx 的ip hash 指令）
		配置指令:balancesource


		2)使用cookie 进行识别
		也就是Haproxy在用户第一次访问的后在用户浏览器插入了一个Cookie，
		用户下一次访问的时候浏览器就会带上这个Cookie给Haproxy，Haproxy进行识别。
		配置指令:cookie  SESSION_COOKIE  insert indirect nocache

		配置例子如下：
		cookie SERVERID insert indirect nocache
		server web01 192.168.56.11:8080 check cookie web01
		server web02 192.168.56.12:8080 check cookie web02
		 


		===========================================================
		会话保持的缺点
		1无法保证绝对负载均衡
		2会话丢失


		二、Session会话复制
		Session的第二中处理办法：会话复制。

		会话复制在Tomcat上得到了支持，
		它是基于IP组播（multicast）来完成Session的复制，
		Tomcat的会话复制分为两种：

		1）全局会话复制：利用Delta Manager复制会话中的变更信息到集群中的所有其他节点。
		2）非全局复制：使用Backup Manager进行复制，它会把Session复制给一个指定的备份节


		 三、Session会话共享
		Session存放到哪里？
		它存放在数据库中，性能更快的分布式KV数据中，例如：Memcached和Redis。

		---------------------------------------------------------------
		Tomcat设置Session共享
		可以使用MSM（Memcached Session Manager）来实现同样把Session存放到Memcache中。

		---------------------------------------------------------------





-----------------------------------------------------------------------

LVS+Keepalived高可用环境部署梳理（主主和主从模式）
集群的概念
	计算机集群简称集群是一种计算机系统，
	它通过一组松散集成的计算机软件和/或硬件连接起来高度紧密地协作完成计算工作。
	在某种意义上，他们可以被看作是一台计算机。
	集群系统中的单个计算机通常称为节点
	通常通过局域网连接，但也有其它的可能连接方式。

	集群计算机通常用来改进单个计算机的计算速度和/或可靠性
	集群计算机比单个计算机，比如工作站或超级计算机性能价格比要高得多。
	集群就是一组独立的计算机，通过网络连接组合成一个组合来共同完一个任务。


	其实集群：就是一组相互独立的计算机，通过高速的网络组成一个计算机系统，
	每个集群节点都是运行其自己进程的一个独立服务器。
	对网络用户来讲，网站后端就是一个单一的系统，协同起来向用户提供系统资源，系统服务。





为什么要使用集群
------------集群的特点------------
	1）高性能performance。
		需要很强的计算能力 天气预报，核试验，
		不是几台计算机能够搞定的。这需要上千台一起来完成这个工作的
	2）价格有效性。

	3）可伸缩性
		服务负载压力大时候，可以扩展来满足服务
	4）高可用性
		满足7*24小时运行



------------集群的优势-------------
1）透明性
2）高性能
3）可管理性
4）可编程性


-----------集群分类及不同分类的特点-----------
计算机集群架构按照功能和结构一般分成以下几类：
1）负载均衡集群（Loadbalancingclusters）简称LBC
2）高可用性集群（High-availabilityclusters）简称HAC
3）高性能计算集群（High-perfomanceclusters）简称HPC
4）网格计算（Gridcomputing）


网络上面一般认为是有三个，负载均衡和高可用集群式我们互联网行业常用的集群架构。

1）负载均衡集群
	负载均衡集群为企业提供了更为实用，性价比更高的系统架构解决方案。

	负载均衡集群把很多客户集中访问的请求负载压力可能尽可能平均的分摊到计算机集群中处理。
	客户请求负载通常包括应用程度处理负载和网络流量负载。
	这样的系统非常适合向使用同一组应用程序为大量用户提供服务。
	每个节点都可以承担一定的访问请求负载压力，
	并且可以实现访问请求在各节点之间动态分配，以实现负载均衡。

	负载均衡运行时，一般通过一个或多个前端负载均衡器将客户访问请求分发到后端一组服务器上，
	从而达到整个系统的高性能和高可用性。这样计算机集群有时也被称为服务器群。
	一般高可用性集群和负载均衡集群会使用类似的技术，
	或同时具有高可用性与负载均衡的特点。

	服务器集群
	分摊请求压力到不同的服务器节点


	负载均衡集群的作用：
	a）分担访问流量（负载均衡）
	b）保持业务的连续性（高可用）


2）高可用性集群
	一般是指当集群中的任意一个节点失效的情况下，
	节点上的所有任务自动转移到其他正常的节点上，
	并且此过程不影响整个集群的运行，不影响业务的提供。

	类似是集群中运行着两个或两个以上的一样的节点，
	当某个主节点出现故障的时候，
	那么其他作为从 节点的节点就会接替主节点上面的任务。
	从节点可以接管主节点的资源（IP地址，架构身份等），
	此时用户不会发现提供服务的对象从主节点转移到从节点。

	高可用性集群的作用：
	当一个机器宕机另一台进行接管。
	比较常用的高可用集群开源软件有：keepalive，heardbeat。


	心跳
	虚拟ip
	主备模式



3）高性能计算集群
	高性能计算集群采用将计算任务分配到集群的不同计算节点儿提高计算能力，
	因而主要应用在科学计算领域。
	比较流行的HPC采用Linux操作系统和其它一些免费软件来完成并行运算。
	这一集群配置通常被称为Beowulf集群。
	这类集群通常运行特定的程序以发挥HPCcluster的并行能力。
	这类程序一般应用特定的运行库, 比如专为科学计算设计的MPI库。

	HPC集群特别适合于在计算中各计算节点之间发生大量数据通讯的计算作业，
	比如一个节点的中间结果或影响到其它节点计算结果的情况。



常用集群软硬件
常用开源集群软件有：lvs，keepalived，haproxy，nginx，apache，heartbeat
常用商业集群硬件有：F5,Netscaler，Radware，A10等



LVS负载均衡集群介绍

负载均衡集群的作用：
	提供一种廉价、有效、透明的方法，
	来扩展网络设备和服务器的负载带宽、
	增加吞吐量，
	加强网络数据处理能力、
	提高网络的灵活性和可用性。


1）把单台计算机无法承受的大规模的并发访问或数据流量分担到多台节点设备上分别处理，
	减少用户等待响应的时间，提升用户体验。

	高并发数据压力分担到多台节点服务器处理，提升响应时间，用户体验

2）单个重负载的运算分担到多台节点设备上做并行处理，每个节点设备处理结束后，
	将结果汇总，返回给用户，系统处理能力得到大幅度提高。

	大量计算分担到多个计算机上做并行计算，提高计算能力

3）7*24小时的服务保证，任意一个或多个设备节点设备宕机，不能影响到业务。
	在负载均衡集群中，所有计算机节点都应该提供相同的服务，集群负载均衡获取所有
	对该服务的如站请求。

	7*24小时的服务保证



LVS是什么？

LVS是linux virtual server的简写linux虚拟服务器，
是一个虚拟的服务器集群系统，可以在unix/linux平台下实现负载均衡集群功能。
该项目在1998年5月由章文嵩博士组织成立。
LVS是一种集群(Cluster)技术，采用IP负载均衡技术和基于内容请求分发技术。
调度器具有很好的吞吐率，
将请求均衡地转移到不同的服务器上执行，且调度器自动屏蔽掉服务器
的故障，从而将一组服务器构成一个高性能的、高可用的虚拟服务器。
整个服务器集群的结构对客户是透明的，而且无需修改客户端和服务器端的程序。


LVS在设计时需要考虑系统的透明性、可伸缩性、高可用性和易管理性。一般来说，
LVS集群采用三层结构


user --Internet--Virtual IP Address
	 |
	 |Loa Balancer
	 |
	 --Load Balancer --heartbreat--BackUP
	 |
	 |Server Cluster
	 |
	 --Real Server1
	 --Real server2
	 --Real Server n
	 |
	 |Storage
	 |
	 Database
	 NetWork File System
	 Distributed File system



LVS集群的特点
1）IP负载均衡与负载调度算法
	IP负载均衡技术
		基于DNS域名轮流解析的方法、
		基于客户端调度访问的方法、
		基于应用层系统负载的调度方法，
		基于IP地址的调度方法

		个虚拟IP一般称为LVS的VIP，

		请求首先经过VIP到达负载调度器，
		然后由负载调度器从Real Server列表中选取一个服
		务节点响应用户的请求。

	负载调度算法
	IPVS实现了如下八种负载调度算法：rr、wrr、Wlc、Dh、SH、Lc、Lblc

2）高可用性
	LVS是一个基于内核级别的应用软件
	具有很高的处理性能，后端服务器可运行任何支持TCP/IP的操作系统
	Linux，各种Unix（如FreeBSD、Sun Solaris、HP Unix等），
	Mac/OS和Windows NT/2000等。
	负载调度器能够支持绝大多数的TCP和UDP协议：

3）性能
	LVS服务器集群系统具有良好的伸缩性，可支持几百万个并发连接。
	超高负荷的服务能力，可支持上百万个并发连接请求。

3）高可靠性
	LVS做的负载均衡系统，运行很长时间，从未做过重新启动。
	几乎不用重启服务器

4）适用环境
	LVS对前端Director Server目前仅支持Linux和FreeBSD系统，但是支持大多数的TCP和UDP协议
	支持TCP协议的应用有：
		HTTP，HTTPS ，FTP，SMTP，，POP3，IMAP4，PROXY，LDAP，SSMTP
	支持UDP协议的应用有：
		DNS，NTP，ICP，视频、音频流播放协议

5）开源软件（软件许可证）
	LVS集群软件是按GPL（GNU Public License）许可证发行的自由软件，
	因此，使用者可以得到软件的源代码，并且可以根据自己的需要进行各种修改，
	但是修改必须是以GPL方式发行。



user PC
|
|Internet
|
Virtual Server
|
|--Load Balancer - Linux Box
|--LAN/WAN
|--Real ser1
|--Real ser2
|--Real sern


在
nginx.conf
虚拟主机就是 一个server段；
一个server段就是一个虚拟主机；

虚拟主机有三种方式
1. 基于端口
2. 基于IP
3. 基于域名


-----------------------------
FIP
VIP
在HA高可用
虚拟IP在主节点上
虚拟IP叫 FIP
f = float 漂浮的意思 


-----------------------------

vip就是lvs自身的公网IP



点睛没用 lvs，到达不到那个量级
用的nginx，nginx也没做 高可用；

nginx最多也就6W左右并发
用户空间和内核空间 

80默认是http端口，这是大家默认遵循的；
有系统文件定义了 
cat /etc/services 

（********）
nginx是用户空间； lvs是内核空间

用户空间和内核空间最大的一个区别是， 
内核没有套接字的限制

用户空间有套接字的限制


套接字明白吧 socket=ip+port

一个系统 最大的套接字是有限制的 65535
tcp 65535 udp 65535

所以最大并发6W左右
最大能承载6w个socket链接


小于 1024的端口只能管理员运行 
以管理员的身份运行进程
很多程序不是以管理员身份运行程序

就像 80端口默认是http端口

点睛的  nginx，tomcat都是普通用户运行的程序
普通用户是不能使用 小于1024的端口的；

cat /etc/services 
nginx有两种进程
一种是主进程， 也叫监听进程
就是root身份运行的 
还有一种是工作进程  worker进程
还有一种是工作进程  worker进程
你可以ps 看一下 
ps aux | grep nginx
root     26051  0.0  0.0 103324   872 pts/7    S+   17:34   0:00 grep nginx
这个数主进程，身下的都是worker进程
以root身份进程监听80套接字





linux将内核 分为 四个环   0， 1 ，2 ，3
1,, 2 历史原因没有使用 
0 是特权模式， 内核空间 ，执行硬件操作 
3 用户空间  用户进程使用， 用户进程需要操作硬件只能通过内核的系统调用进行

底层知识是还是很重要的 



docker
还在用kvm（就是Keyboard Video Mouse的缩写）
容器三个概念，   镜像，仓库，容器
我一个java web程序，如何和docker发布呢

你先做一个镜像，这个镜像中有tomcat，java运行环境，
然后在启动 容器的时候将你的代码映射到 容器 中就是tomcat的访问目录中就行了

代码放在哪？
放到docker宿主机的一个路径下，将这个路径映射到容器的 tomcat访问路径下就行了；

特性 		容器 				虚拟机
启动 		秒级 				分钟级
磁盘使用   一般MB  				一般GB
性能		接近原生			弱于原生
系统支持量	单机支持千个容器 	一般几十个
安全性 		存在风险	    	不存在风险
使用要求  	Kernel>3.10 		需要硬件CPU虚拟化技术支持

docker可以理解大大提高资源利用率了

一般发布都是docker+jenkins 自动化部署














